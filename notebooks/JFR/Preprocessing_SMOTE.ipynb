{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  One_hot_encoding for nominal data \n",
    "2.  Decode Employment Occupation with WEight of Evidence (WOE)\n",
    "3.  Decoding Ordinal string Data to ordinal string Data \n",
    "4.  Impute Missing Values with Mean \n",
    "5.  Rename Colums\n",
    "6.  Check for Multicoliniarity -> Drop Columns\n",
    "7.  Balance Dataset\n",
    "8.  Save Version of datasets\n",
    "9.  Standardize Datasets \n",
    "10. Save Versions \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent.parent / \"data\" / \"raw\"\n",
    "raw_df = pd.read_csv(data_path / \"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "labels_df = pd.read_csv(data_path / \"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "test_df = pd.read_csv(data_path / \"test_set_features.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "all_df = raw_df.join(labels_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-enconding without employment_occuptation (employment_occuptation -> Weight of Evidence Encoded)\n",
    "    # drop column employment_occupation \n",
    "    # identify columns with categorial data \n",
    "    # just use columns with nominal data\n",
    "    # getdummies() -> drop first column to dismiss multicollinarity, keep NaN column\n",
    "raw_df = raw_df.drop(columns = ['employment_occupation'])\n",
    "\n",
    "non_numerical_obj = raw_df.columns[raw_df.dtypes == \"object\"]\n",
    "non_numerical_obj\n",
    "\n",
    "nominal_list = ['race', 'sex', \n",
    "       'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region',\n",
    "       'census_msa', 'employment_industry']\n",
    "\n",
    "raw_df_encoded = pd.get_dummies(raw_df, columns=nominal_list, drop_first = True, dummy_na=True)\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=nominal_list, drop_first = True, dummy_na=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of Evidence Encoding of Occuptation on raw_data\n",
    "# 'h1n1_vaccine', 'seasonal_vaccine' \n",
    "def WOE(var, tar):\n",
    "    all_df[var] = all_df[var].fillna('NoData')\n",
    "    k = all_df[[var,tar]].groupby(var)[tar].agg(['count','sum']).reset_index()\n",
    "    k.columns = [var,'Count','Good']\n",
    "    k['Bad'] = k['Count'] - k['Good']\n",
    "    k['Good %'] = (k['Good'] / k['Good'].sum()*100).round(2)\n",
    "    k['Bad %'] = (k['Bad'] / k['Bad'].sum()*100).round(2)\n",
    "    k[var+tar+'_WOE'] = np.log(k['Good %'] / k['Bad %']).round(2)\n",
    "    k = k.sort_values(by=var+tar+'_WOE')\n",
    "    return(k)\n",
    "h1n1_WOE = WOE('employment_occupation' , 'h1n1_vaccine')\n",
    "seasonal_WOE = WOE('employment_occupation' , 'seasonal_vaccine')\n",
    "\n",
    "WOE_df_season = pd.merge(all_df[['seasonal_vaccine','employment_occupation']],seasonal_WOE[['employment_occupation','employment_occupationseasonal_vaccine_WOE']],\n",
    "     left_on='employment_occupation',\n",
    "     right_on='employment_occupation',how='left')\n",
    "WOE_df_h1n1 = pd.merge(all_df[['h1n1_vaccine','employment_occupation']],h1n1_WOE[['employment_occupation','employment_occupationh1n1_vaccine_WOE']],\n",
    "     left_on='employment_occupation',\n",
    "     right_on='employment_occupation',how='left')\n",
    "\n",
    "\n",
    "WOE_df_both = WOE_df_h1n1.join(WOE_df_season, lsuffix='_h1n1', rsuffix='_seasonal')\n",
    "WOE_mean = WOE_df_both[['employment_occupationh1n1_vaccine_WOE', \n",
    "                           'employment_occupationseasonal_vaccine_WOE']].mean(axis = 1)\n",
    "\n",
    "raw_df_encoded['employment_occupation_WOE'] = WOE_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of Evidence Encoding of Occuptation on test_data\n",
    "# 'h1n1_vaccine', 'seasonal_vaccine' \n",
    "test_df_encoded['employment_occupation_new'] =test_df_encoded['employment_occupation'].replace(np.nan, 'NoData')\n",
    "\n",
    "test_WOE_df_season = pd.merge(test_df_encoded['employment_occupation_new'],seasonal_WOE[['employment_occupation','employment_occupationseasonal_vaccine_WOE']],\n",
    "     left_on='employment_occupation_new',\n",
    "     right_on='employment_occupation',how='left')\n",
    "test_WOE_df_season.index =  test_df_encoded.index\n",
    "\n",
    "test_WOE_df_h1n1 = pd.merge(test_df_encoded[['employment_occupation_new']],h1n1_WOE[['employment_occupation','employment_occupationh1n1_vaccine_WOE']],\n",
    "     left_on='employment_occupation_new',\n",
    "     right_on='employment_occupation',how='left')\n",
    "test_WOE_df_h1n1.index =  test_df_encoded.index\n",
    "\n",
    "\n",
    "test_WOE_df_both = test_WOE_df_h1n1 .join(test_WOE_df_season, lsuffix='_h1n1', rsuffix='_seasonal')\n",
    "\n",
    "test_WOE_df_both.index =  test_df_encoded.index\n",
    "\n",
    "\n",
    "test_df_encoded['employment_occupation_WOE'] = test_WOE_df_both[['employment_occupationh1n1_vaccine_WOE', \n",
    "                           'employment_occupationseasonal_vaccine_WOE']].mean(axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "test_df_encoded = test_df_encoded.drop(columns = ['employment_occupation','employment_occupation_new' ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of ordinal data \n",
    "    # identifiying ordinal data columns \n",
    "    # change NaN in ordinal data columns to most frequent value \n",
    "    # change strings in ordinal data to numbers \n",
    "    # delete values in columns wich where imputed with most frequent values\n",
    "    # impute NaN values with KNN\n",
    "    \n",
    "ordinal_list = ['age_group','education', 'income_poverty' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute misssing values in ordinal data columns with most frequent value \n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "raw_df_encoded_mode = imp_mode.fit_transform(raw_df_encoded[ordinal_list])\n",
    "raw_df_encoded_mode_pd = pd.DataFrame(raw_df_encoded_mode, index = raw_df_encoded.index)\n",
    "\n",
    "raw_df_encoded['age_group'] = raw_df_encoded_mode_pd[0]\n",
    "raw_df_encoded['education'] = raw_df_encoded_mode_pd[1]\n",
    "raw_df_encoded['income_poverty'] = raw_df_encoded_mode_pd[2]\n",
    "\n",
    "test_imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "test_df_encoded_mode = test_imp_mode.fit_transform(test_df_encoded[ordinal_list])\n",
    "test_df_encoded_mode_pd = pd.DataFrame(test_df_encoded_mode, index = test_df_encoded.index )\n",
    "\n",
    "test_df_encoded['age_group'] = test_df_encoded_mode_pd[0]\n",
    "test_df_encoded['education'] = test_df_encoded_mode_pd[1]\n",
    "test_df_encoded['income_poverty'] = test_df_encoded_mode_pd[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change strings in ordinal data to numbers \n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_enc = OrdinalEncoder ( \n",
    "    categories = [\n",
    "        ['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years'],\n",
    "        ['< 12 Years', '12 Years', 'Some College', 'College Graduate' ],\n",
    "        ['Below Poverty', '<= $75,000, Above Poverty', '> $75,000'],\n",
    "     ]\n",
    ")\n",
    "\n",
    "raw_df_encoded_ordinal = ordinal_enc.fit_transform(raw_df_encoded[ordinal_list])\n",
    "raw_df_encoded_ordinal = pd.DataFrame(raw_df_encoded_ordinal, raw_df_encoded.index)\n",
    "#ordinal_enc.categories_\n",
    "\n",
    "raw_df_encoded['age_group'] = raw_df_encoded_ordinal[0]\n",
    "raw_df_encoded['education'] = raw_df_encoded_ordinal[1]\n",
    "raw_df_encoded['income_poverty'] = raw_df_encoded_ordinal[2]\n",
    "\n",
    "test_df_encoded_ordinal = ordinal_enc.fit_transform(test_df_encoded[ordinal_list])\n",
    "test_df_encoded_ordinal = pd.DataFrame(test_df_encoded_ordinal, test_df_encoded.index)\n",
    "\n",
    "\n",
    "test_df_encoded['age_group'] = test_df_encoded_ordinal[0]\n",
    "test_df_encoded['education'] = test_df_encoded_ordinal[1]\n",
    "test_df_encoded['income_poverty'] = test_df_encoded_ordinal[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## impute missing values with mean\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "raw_df_encoded_imputed = imp_mode.fit_transform(raw_df_encoded)\n",
    "\n",
    "raw_df_encoded_imputed = pd.DataFrame(raw_df_encoded_imputed, columns = raw_df_encoded.columns, index = raw_df_encoded.index)\n",
    "\n",
    "raw_df_median = imp_mode.fit(raw_df_encoded)\n",
    "test_df_encoded_imputed = imp_mode.transform(test_df_encoded)\n",
    "\n",
    "test_df_encoded_imputed = pd.DataFrame(test_df_encoded_imputed, columns = test_df_encoded.columns, index = test_df_encoded.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming\n",
    "raw_df_encoded_imputed_list = raw_df_encoded_imputed.columns.tolist()\n",
    "\n",
    "renamed_list = []\n",
    "for column_name in raw_df_encoded_imputed_list:\n",
    "    column_name = re.sub(pattern=r\"\\$(\\d\\d)....\", repl=\"\\\\1k\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\<\\=|\\<\\s\", repl=\"less_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\>\\=|\\>\\s\", repl=\"gr_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\w)\\,\\s(\\w)\", repl=\"\\\\1_\\\\2\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\s\\-\\s\", repl=\"_-_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\w)\\s+(\\w)\", repl=\"\\\\1_\\\\2\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\d\\+)\\s\", repl=\"\\\\1_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\_\\_\", repl=\"_\", string=column_name)\n",
    "    renamed_list.append(column_name)\n",
    "    \n",
    "raw_df_encoded_imputed.columns = renamed_list\n",
    "test_df_encoded_imputed.columns = renamed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21033\n",
      "1     5674\n",
      "Name: h1n1_vaccine, dtype: int64\n",
      "0    14272\n",
      "1    12435\n",
      "Name: seasonal_vaccine, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13295</td>\n",
       "      <td>7738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>977</td>\n",
       "      <td>4697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "seasonal_vaccine      0     1\n",
       "h1n1_vaccine                 \n",
       "0                 13295  7738\n",
       "1                   977  4697"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels_df['h1n1_vaccine'].value_counts())\n",
    "print(labels_df['seasonal_vaccine'].value_counts())\n",
    "pd.crosstab(labels_df['h1n1_vaccine'],labels_df['seasonal_vaccine'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vacc(df):\n",
    "    if (df['h1n1_vaccine'] == 0) and (df['seasonal_vaccine'] == 0):\n",
    "        return 0\n",
    "    elif (df['h1n1_vaccine'] == 1) and (df['seasonal_vaccine'] == 0):\n",
    "        return 1\n",
    "    elif (df['h1n1_vaccine'] == 0) and (df['seasonal_vaccine'] == 1):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['one_column_vaccine'] = labels_df.apply(one_vacc, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13295\n",
      "2     7738\n",
      "3     4697\n",
      "1      977\n",
      "Name: one_column_vaccine, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labels_df['one_column_vaccine'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "raw_df_encoded_imputed_balanced, labels_df_balanced = oversample.fit_resample(raw_df_encoded_imputed, labels_df['one_column_vaccine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    13295\n",
      "2    13295\n",
      "1    13295\n",
      "0    13295\n",
      "Name: one_column_vaccine, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(53180, 74)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels_df_balanced.value_counts())\n",
    "raw_df_encoded_imputed_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_h1n1(df):\n",
    "    if (df['one_column_vaccine'] == 1) or (df['one_column_vaccine'] == 3) :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def reverse_seasonal(df):\n",
    "    if (df['one_column_vaccine'] == 2) or (df['one_column_vaccine'] == 3) :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_balanced_pd = pd.DataFrame(labels_df_balanced, columns = ['one_column_vaccine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53180,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df_balanced_pd['one_column_vaccine'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_column_vaccine</th>\n",
       "      <th>h1n1_vaccine_new</th>\n",
       "      <th>seasonal_vaccine_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one_column_vaccine  h1n1_vaccine_new  seasonal_vaccine_new\n",
       "0                   0                 0                     0\n",
       "1                   2                 0                     1\n",
       "2                   0                 0                     0\n",
       "3                   2                 0                     1\n",
       "4                   0                 0                     0\n",
       "5                   0                 0                     0\n",
       "6                   0                 0                     0\n",
       "7                   3                 1                     1\n",
       "8                   0                 0                     0\n",
       "9                   0                 0                     0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df_balanced_pd['h1n1_vaccine_new'] = labels_df_balanced_pd.apply(reverse_h1n1, axis = 1)\n",
    "labels_df_balanced_pd['seasonal_vaccine_new'] = labels_df_balanced_pd.apply(reverse_seasonal, axis = 1)\n",
    "\n",
    "labels_df_balanced_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_status_nan                 marital_status_nan                      0.907403\n",
       "marital_status_nan                    employment_status_nan                   0.907403\n",
       "rent_or_own_nan                       employment_status_nan                   0.810347\n",
       "employment_status_nan                 rent_or_own_nan                         0.810347\n",
       "employment_industry_nan               employment_status_Not_in_Labor_Force    0.809612\n",
       "employment_status_Not_in_Labor_Force  employment_industry_nan                 0.809612\n",
       "rent_or_own_nan                       marital_status_nan                      0.787514\n",
       "marital_status_nan                    rent_or_own_nan                         0.787514\n",
       "health_worker                         employment_industry_fcxhlnwr            0.743144\n",
       "employment_industry_fcxhlnwr          health_worker                           0.743144\n",
       "behavioral_outside_home               behavioral_large_gatherings             0.620156\n",
       "behavioral_large_gatherings           behavioral_outside_home                 0.620156\n",
       "doctor_recc_h1n1                      doctor_recc_seasonal                    0.568222\n",
       "doctor_recc_seasonal                  doctor_recc_h1n1                        0.568222\n",
       "race_Hispanic                         race_White                              0.563850\n",
       "race_White                            race_Hispanic                           0.563850\n",
       "opinion_h1n1_risk                     opinion_seas_risk                       0.541451\n",
       "opinion_seas_risk                     opinion_h1n1_risk                       0.541451\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for multi collinarity \n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "corr_data = raw_df_encoded_imputed_balanced.corr().abs()\n",
    "sorted_corr_data = corr_data.unstack().sort_values(ascending=False)\n",
    "ones = corr_data.unstack().sort_values(ascending=False) != 1.0\n",
    "without_ones = sorted_corr_data[ones]\n",
    "NaNs = corr_data.unstack().sort_values(ascending=False).notna()\n",
    "\n",
    "without_ones_and_Na = without_ones[NaNs]\n",
    "big_corrs = corr_data.unstack().sort_values(ascending=False) > 0.5\n",
    "without_ones_and_Na[big_corrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_encoded_imputed_balanced_dropped = raw_df_encoded_imputed_balanced.drop(columns = \n",
    "                                                                               ['marital_status_nan', \n",
    "                                                                                'employment_status_nan',\n",
    "                                                                                'rent_or_own_nan',\n",
    "                                                                                'employment_industry_nan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_encoded_imputed_dropped = test_df_encoded_imputed.drop(columns = ['marital_status_nan', \n",
    "                                                                                'employment_status_nan',\n",
    "                                                                                'rent_or_own_nan',\n",
    "                                                                                'employment_industry_nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "health_worker                 employment_industry_fcxhlnwr    0.743144\n",
       "employment_industry_fcxhlnwr  health_worker                   0.743144\n",
       "behavioral_outside_home       behavioral_large_gatherings     0.620156\n",
       "behavioral_large_gatherings   behavioral_outside_home         0.620156\n",
       "doctor_recc_h1n1              doctor_recc_seasonal            0.568222\n",
       "doctor_recc_seasonal          doctor_recc_h1n1                0.568222\n",
       "race_White                    race_Hispanic                   0.563850\n",
       "race_Hispanic                 race_White                      0.563850\n",
       "opinion_h1n1_risk             opinion_seas_risk               0.541451\n",
       "opinion_seas_risk             opinion_h1n1_risk               0.541451\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "corr_data = raw_df_encoded_imputed_balanced_dropped.corr().abs()\n",
    "sorted_corr_data = corr_data.unstack().sort_values(ascending=False)\n",
    "ones = corr_data.unstack().sort_values(ascending=False) != 1.0\n",
    "without_ones = sorted_corr_data[ones]\n",
    "NaNs = corr_data.unstack().sort_values(ascending=False).notna()\n",
    "\n",
    "without_ones_and_Na = without_ones[NaNs]\n",
    "big_corrs = corr_data.unstack().sort_values(ascending=False) > 0.5\n",
    "without_ones_and_Na[big_corrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53180, 2)\n",
      "(53180, 70)\n"
     ]
    }
   ],
   "source": [
    "labels_df_balanced_pd_dropped = labels_df_balanced_pd.drop(columns = ['one_column_vaccine'])\n",
    "print(labels_df_balanced_pd_dropped.shape)\n",
    "print(raw_df_encoded_imputed_balanced_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_balanced_pd_dropped.index.rename('respondent_id', inplace = True)\n",
    "raw_df_encoded_imputed_balanced_dropped.index.rename('respondent_id', inplace = True)\n",
    "test_df_encoded_imputed_dropped.index.rename('respondent_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_preprocessed = Path.cwd().parent.parent / \"data\" / \"processed\"\n",
    "\n",
    "labels_df_balanced_pd_dropped.to_csv (data_path_preprocessed / \n",
    "    'training_set_labels__balanced.csv')\n",
    "raw_df_encoded_imputed_balanced_dropped.to_csv (data_path_preprocessed / \n",
    "    'training_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_dropped.csv')\n",
    "test_df_encoded_imputed_dropped.to_csv (data_path_preprocessed / \n",
    "    'test_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_dropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_encoded_imputed_balanced.index.rename('respondent_id', inplace = True)\n",
    "test_df_encoded_imputed.index.rename('respondent_id', inplace = True)\n",
    "raw_df_encoded_imputed_balanced.to_csv (data_path_preprocessed / \n",
    "    'training_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced.csv')\n",
    "test_df_encoded_imputed.to_csv (data_path_preprocessed / \n",
    "    'test_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "raw_df_encoded_imputed_balanced_dropped_stand = scaler.fit_transform(raw_df_encoded_imputed_balanced_dropped)\n",
    "raw_df_encoded_imputed_balanced_dropped_stand = pd.DataFrame(raw_df_encoded_imputed_balanced_dropped_stand, columns = raw_df_encoded_imputed_balanced_dropped.columns, index = raw_df_encoded_imputed_balanced_dropped.index)\n",
    "\n",
    "test_df_encoded_imputed_dropped_stand = scaler.fit_transform(test_df_encoded_imputed_dropped)\n",
    "test_df_encoded_imputed_dropped_stand = pd.DataFrame(test_df_encoded_imputed_dropped_stand, columns = test_df_encoded_imputed_dropped.columns, index = test_df_encoded_imputed_dropped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_encoded_imputed_balanced_dropped_stand.to_csv (data_path_preprocessed / \n",
    "    'training_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_dropped_stand.csv')\n",
    "test_df_encoded_imputed_dropped_stand.to_csv (data_path_preprocessed / \n",
    "    'test_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_dropped_stand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_encoded_imputed_balanced_stand = scaler.fit_transform(raw_df_encoded_imputed_balanced)\n",
    "raw_df_encoded_imputed_balanced_stand = pd.DataFrame(raw_df_encoded_imputed_balanced_stand, columns = raw_df_encoded_imputed_balanced.columns, index = raw_df_encoded_imputed_balanced.index)\n",
    "\n",
    "test_df_encoded_imputed_stand = scaler.fit_transform(test_df_encoded_imputed)\n",
    "test_df_encoded_imputed_stand = pd.DataFrame(test_df_encoded_imputed_stand, columns = test_df_encoded_imputed.columns, index = test_df_encoded_imputed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_encoded_imputed_balanced.index.rename('respondent_id', inplace = True)\n",
    "test_df_encoded_imputed.index.rename('respondent_id', inplace = True)\n",
    "raw_df_encoded_imputed_balanced_stand.to_csv (data_path_preprocessed / \n",
    "    'training_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_stand.csv')\n",
    "test_df_encoded_imputed_stand.to_csv (data_path_preprocessed / \n",
    "    'test_set_features__Preprocessing_nominal_ordinal_WOE_Impute_balanced_stand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37-ds]",
   "language": "python",
   "name": "conda-env-py37-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
