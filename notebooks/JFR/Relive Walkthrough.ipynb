{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  One_hot_encoding for ordinal and categorial columns (rank information on education and poverty is lo\n",
    "2.  Check for NAs \n",
    "    -> delete employment columns, health insurance\n",
    "    -> delete rows with no information on recommandation of doctor (poor answering behavior) \n",
    "    -> take rows of opinion columns and impute NAs with k nearest neighbour \n",
    "3.  Delete the same rows in the labels dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent.parent / \"data\" / \"raw\"\n",
    "raw_df = pd.read_csv(data_path / \"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "labels_df = pd.read_csv(data_path / \"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "test_df = pd.read_csv(data_path / \"test_set_features.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.dtypes != \"object\"\n",
    "numeric_cols = raw_df.columns[raw_df.dtypes != \"object\"].values\n",
    "raw_numeric_df = raw_df[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "raw_numeric_scaled_df = scaler.fit_transform(raw_numeric_df)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "raw_numeric_scaled_imputed_df = imp_mode.fit_transform(raw_numeric_scaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    raw_numeric_scaled_imputed_df,\n",
    "    labels_df,\n",
    "    test_size=0.33,\n",
    "    shuffle=True,\n",
    "    stratify=labels_df,\n",
    "    random_state=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70898955, 0.29101045],\n",
       "        [0.90223115, 0.09776885],\n",
       "        [0.84459698, 0.15540302],\n",
       "        ...,\n",
       "        [0.92338355, 0.07661645],\n",
       "        [0.89632571, 0.10367429],\n",
       "        [0.92788007, 0.07211993]]),\n",
       " array([[0.5272201 , 0.4727799 ],\n",
       "        [0.61838567, 0.38161433],\n",
       "        [0.37024072, 0.62975928],\n",
       "        ...,\n",
       "        [0.85937   , 0.14063   ],\n",
       "        [0.77843316, 0.22156684],\n",
       "        [0.15114951, 0.84885049]])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = MultiOutputClassifier(LogisticRegression(penalty=\"l2\", C=1))\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict_proba(X_test)\n",
    "\n",
    "\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions[0].shape (8814, 2)\n",
      "predictions[1].shape (8814, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions[0].shape\", predictions[0].shape)\n",
    "print(\"predictions[1].shape\", predictions[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds.shape: (8814, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>0.291010</td>\n",
       "      <td>0.472780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16516</th>\n",
       "      <td>0.097769</td>\n",
       "      <td>0.381614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0.155403</td>\n",
       "      <td>0.629759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16981</th>\n",
       "      <td>0.661790</td>\n",
       "      <td>0.857877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19111</th>\n",
       "      <td>0.284478</td>\n",
       "      <td>0.776929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_vaccine  seasonal_vaccine\n",
       "respondent_id                                \n",
       "6728               0.291010          0.472780\n",
       "16516              0.097769          0.381614\n",
       "3106               0.155403          0.629759\n",
       "16981              0.661790          0.857877\n",
       "19111              0.284478          0.776929"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = pd.DataFrame(\n",
    "    {\n",
    "        \"h1n1_vaccine\": predictions[0][:, 1],\n",
    "        \"seasonal_vaccine\": predictions[1][:, 1],\n",
    "    },\n",
    "    index = y_eval.index\n",
    ")\n",
    "print(\"y_preds.shape:\", y_preds.shape)\n",
    "y_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294712650703964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change strings in ordinal data to numbers \n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_enc = OrdinalEncoder ( \n",
    "    categories = [\n",
    "        ['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years'],\n",
    "        ['< 12 Years', '12 Years', 'Some College', 'College Graduate' ],\n",
    "        ['Below Poverty', '<= $75,000, Above Poverty', '> $75,000'],\n",
    "     ]\n",
    ")\n",
    "\n",
    "raw_df_encoded_ordinal = ordinal_enc.fit_transform(raw_df_encoded[ordinal_list])\n",
    "raw_df_encoded_ordinal = pd.DataFrame(raw_df_encoded_ordinal)\n",
    "#ordinal_enc.categories_\n",
    "\n",
    "raw_df_encoded['age_group'] = raw_df_encoded_ordinal[0]\n",
    "raw_df_encoded['education'] = raw_df_encoded_ordinal[1]\n",
    "raw_df_encoded['income_poverty'] = raw_df_encoded_ordinal[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete values in columns wich where imputed with most frequent values\n",
    "\n",
    "education_encoded = raw_df_encoded['education'].copy()\n",
    "education_na = raw_df['education'].isna()\n",
    "education_encoded[education_na] = np.nan\n",
    "\n",
    "raw_df_encoded['education'] = education_encoded\n",
    "\n",
    "income_poverty_encoded = raw_df_encoded['income_poverty'].copy()\n",
    "income_poverty_na = raw_df['income_poverty'].isna()\n",
    "income_poverty_encoded[education_na] = np.nan\n",
    "\n",
    "raw_df_encoded['income_poverty'] = income_poverty_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caculate KNN for the whole dataset\n",
    "\n",
    "#import numpy as np\n",
    "#from sklearn.impute import KNNImputer\n",
    "#imputer = KNNImputer(\n",
    "#    missing_values=np.nan,\n",
    "#    n_neighbors=5,\n",
    "#    weights=\"distance\",\n",
    "#    metric=\"nan_euclidean\",\n",
    "#    copy=True,\n",
    "#    add_indicator=False,\n",
    "#)\n",
    "\n",
    "#imputer.fit(raw_df_encoded)\n",
    "\n",
    "#knn_array = imputer.transform(raw_df_encoded)\n",
    "\n",
    "#raw_df_encoded_imputed = pd.DataFrame(knn_array)\n",
    "#raw_df_encoded_imputed.columns = raw_df_encoded.columns\n",
    "\n",
    "#change KNN imputations in ordinal data columns to \"categories\"\n",
    "\n",
    "#raw_df_encoded_imputed['education'].round()\n",
    "#raw_df_encoded_imputed['income_poverty'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternativly to KNN impute missing values with NaN\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "raw_df_encoded_imputed = imp_mode.fit_transform(raw_df_encoded)\n",
    "\n",
    "raw_df_encoded_imputed = pd.DataFrame(raw_df_encoded_imputed, columns = raw_df_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming\n",
    "raw_df_encoded_imputed_list = raw_df_encoded_imputed.columns.tolist()\n",
    "\n",
    "renamed_list = []\n",
    "for column_name in raw_df_encoded_imputed_list:\n",
    "    column_name = re.sub(pattern=r\"\\$(\\d\\d)....\", repl=\"\\\\1k\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\<\\=|\\<\\s\", repl=\"less_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\>\\=|\\>\\s\", repl=\"gr_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\w)\\,\\s(\\w)\", repl=\"\\\\1_\\\\2\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\s\\-\\s\", repl=\"_-_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\w)\\s+(\\w)\", repl=\"\\\\1_\\\\2\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"(\\d\\+)\\s\", repl=\"\\\\1_\", string=column_name)\n",
    "    column_name = re.sub(pattern=r\"\\_\\_\", repl=\"_\", string=column_name)\n",
    "    renamed_list.append(column_name)\n",
    "    \n",
    "raw_df_encoded_imputed.columns = renamed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path_processed = Path.cwd().parent.parent / \"data\" / \"processed\"\n",
    "#raw_df_encoded.to_csv(data_path_processed / \"training_set_features_1hot_na.csv\",)\n",
    "#test_df_encoded.to_csv(data_path_processed / \"test_set_features_1hot_na.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_status_nan                 marital_status_nan                      0.876134\n",
       "marital_status_nan                    employment_status_nan                   0.876134\n",
       "employment_status_Not_in_Labor_Force  employment_industry_nan                 0.789401\n",
       "employment_industry_nan               employment_status_Not_in_Labor_Force    0.789401\n",
       "rent_or_own_nan                       employment_status_nan                   0.770415\n",
       "employment_status_nan                 rent_or_own_nan                         0.770415\n",
       "marital_status_nan                    rent_or_own_nan                         0.742348\n",
       "rent_or_own_nan                       marital_status_nan                      0.742348\n",
       "health_worker                         employment_industry_fcxhlnwr            0.696227\n",
       "employment_industry_fcxhlnwr          health_worker                           0.696227\n",
       "doctor_recc_h1n1                      doctor_recc_seasonal                    0.603152\n",
       "doctor_recc_seasonal                  doctor_recc_h1n1                        0.603152\n",
       "behavioral_large_gatherings           behavioral_outside_home                 0.580881\n",
       "behavioral_outside_home               behavioral_large_gatherings             0.580881\n",
       "opinion_seas_risk                     opinion_h1n1_risk                       0.562976\n",
       "opinion_h1n1_risk                     opinion_seas_risk                       0.562976\n",
       "race_White                            race_Hispanic                           0.521664\n",
       "race_Hispanic                         race_White                              0.521664\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for multi collinarity \n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "corr_data = raw_df_encoded_imputed.corr().abs()\n",
    "sorted_corr_data = corr_data.unstack().sort_values(ascending=False)\n",
    "ones = corr_data.unstack().sort_values(ascending=False) != 1.0\n",
    "without_ones = sorted_corr_data[ones]\n",
    "NaNs = corr_data.unstack().sort_values(ascending=False).notna()\n",
    "\n",
    "without_ones_and_Na = without_ones[NaNs]\n",
    "big_corrs = corr_data.unstack().sort_values(ascending=False) > 0.5\n",
    "without_ones_and_Na[big_corrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in test und train data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    raw_df_encoded_imputed_stand,\n",
    "    labels_df,\n",
    "    shuffle = True,\n",
    "    test_size = 0.25,\n",
    "    random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7354426508244212\n",
      "0.7339868972864074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = MultiOutputClassifier(LogisticRegression(penalty=\"l2\", C=1))\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = logisticRegr.predict(X_test)\n",
    "train_predictions = logisticRegr.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_train, train_predictions))\n",
    "print(roc_auc_score(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37-ds]",
   "language": "python",
   "name": "conda-env-py37-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
