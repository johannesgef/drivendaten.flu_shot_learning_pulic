{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / 'data' / 'processed'\n",
    "SUBMISSION_PATH = Path.cwd().parent / 'models' / 'submissions'\n",
    "\n",
    "algo_name = 'LogReg_1'\n",
    "data_name = 'employ_1hot'\n",
    "date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "training_features_file_name = 'training_set_features_' + data_name + '.csv'\n",
    "training_features_file = DATA_PATH / training_features_file_name\n",
    "test_features_file_name = 'test_set_features_' + data_name + '.csv'\n",
    "test_features_file = DATA_PATH / test_features_file_name\n",
    "\n",
    "training_labels_file = DATA_PATH / 'training_set_labels.csv'\n",
    "submission_format_file = DATA_PATH / \"submission_format.csv\"\n",
    "\n",
    "submission_file_name = algo_name + '_' + data_name + '_' + date + '.csv'\n",
    "submission_file = SUBMISSION_PATH / submission_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "RANDOM_SEED = 6    # Set a random seed for reproducibility!\n",
    "\n",
    "# load data\n",
    "training_features_df = pd.read_csv(training_features_file, index_col=\"respondent_id\")\n",
    "training_labels_df = pd.read_csv(training_labels_file, index_col=\"respondent_id\")\n",
    "\n",
    "numeric_cols = training_features_df.columns[training_features_df.dtypes != \"object\"].values\n",
    "#print(numeric_cols)\n",
    "\n",
    "# chain preprocessing into a Pipeline object\n",
    "# each step is a tuple of (name you chose, sklearn transformer)\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# create the preprocessor stage of final pipeline\n",
    "# each entry in the transformer list is a tuple of\n",
    "# (name you choose, sklearn transformer, list of columns)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", numeric_preprocessing_steps, numeric_cols)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")\n",
    "\n",
    "estimators = MultiOutputClassifier(\n",
    "    estimator=LogisticRegression(penalty=\"l2\", C=1)\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators),\n",
    "])\n",
    "\n",
    "#full_pipeline\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    test_size=0.33,\n",
    "    shuffle=True,\n",
    "    stratify=training_labels_df,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "#%%time\n",
    "\n",
    "# Train model\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on evaluation set\n",
    "# This competition wants probabilities, not labels\n",
    "preds = full_pipeline.predict_proba(X_eval)\n",
    "#preds\n",
    "\n",
    "#print(\"test_probas[0].shape\", preds[0].shape)\n",
    "#print(\"test_probas[1].shape\", preds[1].shape)\n",
    "\n",
    "y_preds = pd.DataFrame(\n",
    "    {\n",
    "        \"h1n1_vaccine\": preds[0][:, 1],\n",
    "        \"seasonal_vaccine\": preds[1][:, 1],\n",
    "    },\n",
    "    index = y_eval.index\n",
    ")\n",
    "#print(\"y_preds.shape:\", y_preds.shape)\n",
    "#y_preds.head()\n",
    "\n",
    "def plot_roc(y_true, y_score, label_name, ax):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    ax.set_ylabel('TPR')\n",
    "    ax.set_xlabel('FPR')\n",
    "    ax.set_title(\n",
    "        f\"{label_name}: AUC = {roc_auc_score(y_true, y_score):.4f}\"\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "\n",
    "plot_roc(\n",
    "    y_eval['h1n1_vaccine'], \n",
    "    y_preds['h1n1_vaccine'], \n",
    "    'h1n1_vaccine',\n",
    "    ax=ax[0]\n",
    ")\n",
    "\n",
    "plot_roc(\n",
    "    y_eval['seasonal_vaccine'], \n",
    "    y_preds['seasonal_vaccine'], \n",
    "    'seasonal_vaccine',\n",
    "    ax=ax[1]\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_eval, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time \n",
    "\n",
    "full_pipeline.fit(training_features_df, training_labels_df)\n",
    "\n",
    "None   # So we don't print out the whole pipeline representation\n",
    "\n",
    "test_features_df = pd.read_csv(test_features_file, index_col=\"respondent_id\")\n",
    "test_probas = full_pipeline.predict_proba(test_features_df)\n",
    "#test_probas\n",
    "\n",
    "submission_df = pd.read_csv(submission_format_file, index_col=\"respondent_id\")\n",
    "#submission_df.head()\n",
    "\n",
    "# Make sure we have the rows in the same order\n",
    "np.testing.assert_array_equal(test_features_df.index.values, submission_df.index.values)\n",
    "\n",
    "# Save predictions to submission data frame\n",
    "submission_df[\"h1n1_vaccine\"] = test_probas[0][:, 1]\n",
    "submission_df[\"seasonal_vaccine\"] = test_probas[1][:, 1]\n",
    "#submission_df.head()\n",
    "\n",
    "submission_df.to_csv(submission_file, index=True)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drivendata-flu_shot]",
   "language": "python",
   "name": "conda-env-drivendata-flu_shot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
